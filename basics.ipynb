{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch is a pretty nice library, from what I've seen so far. \n",
    "This tutorial follows the \n",
    "[introductory](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py) tutorial. I'll leave references where I diverge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing torch is . . . nice, and you don't have to alias it, \n",
    "because the name isn't a paragraph long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interacting with CUDA enabled devices has also been easy,\n",
    "straigthforward, and feature packed.\n",
    "\n",
    "[Torch CUDA Docs](https://pytorch.org/docs/stable/cuda.html?highlight=cuda#module-torch.cuda)\n",
    "\n",
    "There are also additional functions to easily handle memory management,\n",
    "cross device communication, and data movement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Current BLAS Handle: 94143602460880\n",
      "[+] Current Device: 0\n",
      "[+] Current Stream: <torch.cuda.Stream device=cuda:0 cuda_stream=0x0>\n",
      "[+] Current Device Count: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'[+] Current BLAS Handle: {torch.cuda.current_blas_handle()}')\n",
    "print(f'[+] Current Device: {torch.cuda.current_device()}')\n",
    "print(f'[+] Current Stream: {torch.cuda.current_stream()}')\n",
    "print(f'[+] Current Device Count: {torch.cuda.device_count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving tensors around devices is easy with the `.to` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(5, 5)\n",
    "y = torch.ones_like(x)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "x.to(device)\n",
    "\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] x: tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "[+] y: tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(f'[+] x: {x}')\n",
    "print(f'[+] y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Random Tensor:\n",
      "tensor([[0.7088, 0.0513, 0.1381, 0.7639, 0.7697],\n",
      "        [0.3305, 0.2283, 0.8394, 0.9281, 0.6790],\n",
      "        [0.4273, 0.5145, 0.2997, 0.6779, 0.8971],\n",
      "        [0.3548, 0.5899, 0.2742, 0.5508, 0.6908],\n",
      "        [0.1419, 0.3622, 0.7334, 0.6258, 0.2114]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 5)\n",
    "print(f'[+] Random Tensor:\\n{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Tensor With Specified Data Type (long):\n",
      "tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 5, dtype=torch.long)\n",
    "print(f'[+] Tensor With Specified Data Type (long):\\n{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] From Numpy Array:\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], dtype=torch.float64)\n",
      "[+] From Python List:\n",
      "tensor([5.0000, 4.5000, 6.7000])\n"
     ]
    }
   ],
   "source": [
    "# Tensors can be constructed from data directly.\n",
    "import numpy as np\n",
    "\n",
    "x = np.ones((5, 5))\n",
    "y = torch.tensor(x)\n",
    "z = torch.tensor([5.0, 4.5, 6.7])\n",
    "\n",
    "print(f'[+] From Numpy Array:\\n{y}')\n",
    "print(f'[+] From Python List:\\n{z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create tensors based on other tensors.\n",
    "These will mirror the properties of the original \n",
    "tensor, unless explicitly specified. This includes\n",
    "data type.\n",
    "\n",
    "When calling `torch.Tensor.new_*()`. The datatype of\n",
    "the allocated values will match that of the original\n",
    "tensor. Though the size has to be specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] x:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((5, 5), dtype=torch.float)\n",
    "x = x.new_ones(5, 3)\n",
    "print(f'[+] x:\\n{x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `*_like()` methods behave the same. They\n",
    "will share the datatype unless otherwise specififed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Random With Same Data Type:\n",
      "tensor([[ 0.0204, -0.7842,  0.1891, -1.6255, -0.5185],\n",
      "        [-0.3987,  0.6290,  1.6027,  0.0829,  1.0554],\n",
      "        [ 1.2418, -2.3342,  1.3321,  0.8430,  0.0399],\n",
      "        [-0.3995, -0.6974,  1.9661, -0.2528,  0.1039],\n",
      "        [-1.2914, -1.4067,  0.6872, -1.4799, -0.2913]])\n",
      "[+] Random With Specified Data Type:\n",
      "tensor([[-0.3544,  0.4366, -1.1455, -0.9615, -1.6178],\n",
      "        [-0.5426, -1.4451, -1.4246, -0.4415,  1.7996],\n",
      "        [-0.0194, -1.6750, -1.0420, -0.6141,  0.5710],\n",
      "        [ 1.1370, -0.1802,  1.2201, -0.9857, -0.0550],\n",
      "        [-0.1125, -1.5007, -1.4354,  0.1511,  0.6555]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((5, 5), dtype=torch.float)\n",
    "y = torch.randn_like(x)\n",
    "z = torch.randn_like(x, dtype=torch.double)\n",
    "\n",
    "print(f'[+] Random With Same Data Type:\\n{y}')\n",
    "print(f'[+] Random With Specified Data Type:\\n{z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the `.size()` of a tensor returns a tensor\n",
    "with the dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] x.size(): torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f'[+] x.size(): {x.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations can be done via operator overloading\n",
    "in some cases. Note that `*` performs elementwise\n",
    "multiplication, as does `Tensor.mul(a, b)`. For \n",
    "matrix multiplication, use `Tensor.matmul(a, b)`.\n",
    "\n",
    "For full details on torch operations, see\n",
    "[Operations](https://pytorch.org/docs/stable/torch.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7031, 0.7031, 0.7031],\n",
       "        [1.8957, 1.8957, 1.8957],\n",
       "        [1.9989, 1.9989, 1.9989],\n",
       "        [2.3096, 2.3096, 2.3096],\n",
       "        [1.6977, 1.6977, 1.6977]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((5, 3))\n",
    "y = torch.ones_like(x)\n",
    "\n",
    "print(x + y == torch.add(x, y))\n",
    "\n",
    "print(x * y == torch.mul(x, y))\n",
    "\n",
    "x = torch.rand((5, 3))\n",
    "y = torch.ones((3, 3), dtype=torch.float)\n",
    "x.matmul(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations can also be performed in place. Any\n",
    "method with `_` at the end modifies data in place.\n",
    "For example `x.t_()` will transpose `x` in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] x:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "[+] x.t:\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((5, 3))\n",
    "print(f'[+] x:\\n{x}')\n",
    "x.t_()\n",
    "print(f'[+] x.t:\\n{x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch Tensors support numpy style indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] x:\n",
      "tensor([[-1.2415,  0.7700, -0.2028,  0.3694,  0.2475, -0.4516],\n",
      "        [ 0.6865, -0.4636, -0.5509,  0.9202,  0.2195, -0.2910],\n",
      "        [ 0.5653, -0.4738,  1.4267, -0.9469, -1.8921,  0.3963],\n",
      "        [ 0.2283, -0.0609,  1.3677, -1.6544,  1.0972, -0.2172],\n",
      "        [ 0.7387, -1.0990, -0.2476,  0.3265,  0.1526, -0.3760]])\n",
      "\n",
      "[+] Fourth Column x[:, 3]:\n",
      "tensor([ 0.3694,  0.9202, -0.9469, -1.6544,  0.3265])\n",
      "\n",
      "[+] Second Row x[1, :]:\n",
      "tensor([ 0.6865, -0.4636, -0.5509,  0.9202,  0.2195, -0.2910])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((5, 6))\n",
    "print(f'[+] x:\\n{x}\\n')\n",
    "print(f'[+] Fourth Column x[:, 3]:\\n{x[:, 3]}\\n')\n",
    "print(f'[+] Second Row x[1, :]:\\n{x[1, :]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] x:\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((5, 5))\n",
    "x.add_(1)\n",
    "print(f'[+] x:\\n{x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way reshaping is done in torch is ideal. The method\n",
    "`.view()` returns a view of the memory location of the\n",
    "original tensor with the specified shape. So, if you \n",
    "modify the original tensor, the view created will refer\n",
    "to the data in that original tensor. Now, if the original\n",
    "tensor is overwritten, such as when using `x = torch.zeros()`,\n",
    "the views will still point to the original memory location, \n",
    "and won't be modified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] x:\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "\n",
      "[+] y:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "[+] z:\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((4, 4))\n",
    "y = x.view((16))\n",
    "z = x.view((8, 2))\n",
    "\n",
    "print(f'[+] x:\\n{x}\\n')\n",
    "print(f'[+] y:\\n{y}\\n')\n",
    "print(f'[+] z:\\n{z}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] x:\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "\n",
      "[+] y:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "[+] z:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.add_(1)\n",
    "\n",
    "print(f'[+] x:\\n{x}\\n')\n",
    "print(f'[+] y:\\n{y}\\n')\n",
    "print(f'[+] z:\\n{z}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] x:\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "\n",
      "[+] y:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((5, 5))\n",
    "print(f'[+] x:\\n{x}\\n')\n",
    "print(f'[+] y:\\n{y}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use numpy bridges to read the\n",
    "memory location of a tensor in numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] n:\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n",
      "\n",
      "[+] n:\n",
      "[[2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, 5)\n",
    "n = x.numpy()\n",
    "\n",
    "print(f'[+] n:\\n{n}\\n')\n",
    "x.add_(1)\n",
    "print(f'[+] n:\\n{n}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we can construct tensor views over numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] b:\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "\n",
      "[+] b:\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "\n",
    "print(f'[+] b:\\n{b}\\n')\n",
    "np.add(a, 1, out=a)\n",
    "print(f'[+] b:\\n{b}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
